{
    "benchmark_name": "10-q Quarterly Report Parser",
    "purpose": "Evaluate the ability of a language model to parse a 10-q quarterly report.",
    "base_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {{information_to_parse}}\n</information-to-extract>\n",
    "prompt_iterations": [
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"speakers\": \"json list of full names of speakers on the call sorted by the order they spoke, no duplicates, include Operator\"\n}\n"
            },
            "expectation": {
                "speakers": [
                    "Kenneth Dorell",
                    "Mark Zuckerberg",
                    "Susan Li",
                    "Operator",
                    "Brian Nowak",
                    "Eric Sheridan",
                    "Mark Shmulik",
                    "Justin Post",
                    "Douglas Anmuth",
                    "Ronald Josey",
                    "Kenneth Gawrelski",
                    "Ross Sandler"
                ]
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"ceo\": \"full name of the CEO\"\n}\n"
            },
            "expectation": {
                "ceo": "Mark Zuckerberg"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"cfo\": \"full name of the CFO\"\n}\n"
            },
            "expectation": {
                "cfo": "Susan Li"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"company\": \"name of the company exactly as listed in the report\"\n}\n"
            },
            "expectation": {
                "company": "Meta Platforms, Inc. (META)"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"conference_call_title\": \"exact title of the conference call\"\n}\n"
            },
            "expectation": {
                "conference_call_title": "Fourth Quarter 2024 Results Conference Call"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"report_date\": \"the date of the conference call as mentioned in the transcript\"\n}\n"
            },
            "expectation": {
                "report_date": "January 29th, 2025"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"quarter\": \"the quarter being reported in this format: QN YYYY\"\n}\n"
            },
            "expectation": {
                "quarter": "Q4 2024"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"total_revenue\": \"Q4 total revenue as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "total_revenue": "$48,400,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"total_expenses\": \"Q4 total expenses as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "total_expenses": "$25,000,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"operating_income\": \"Q4 operating income as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "operating_income": "$23,400,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"operating_margin\": \"Q4 operating margin percentage as stated in the report with a percentage sign on the last number nothing else\"\n}\n"
            },
            "expectation": {
                "operating_margin": "48%"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"net_income\": \"Q4 net income as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "net_income": "$20,800,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"earnings_per_share\": \"Q4 earnings per share as stated in the report exact number and nothing else with dollar sign\"\n}\n"
            },
            "expectation": {
                "earnings_per_share": "$8.02"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"employee_count\": \"exact number of employees at year end comma separated\"\n}\n"
            },
            "expectation": {
                "employee_count": "74,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"family_of_apps_ad_revenue\": \"Q4 Family of Apps ad revenue as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "family_of_apps_ad_revenue": "$46,800,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"family_of_apps_other_revenue\": \"Q4 Family of Apps other revenue as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "family_of_apps_other_revenue": "$519,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"reality_labs_revenue\": \"Q4 revenue for Reality Labs as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "reality_labs_revenue": "$1,100,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"reality_labs_operating_loss\": \"operating loss for Reality Labs in Q4 as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "reality_labs_operating_loss": "$5,000,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"future_q1_2025_revenue_range\": \"Q1 2025 revenue guidance range as stated in the report fully written out with commas with a dash between the range no spaces and dollar sign on both numbers\"\n}\n"
            },
            "expectation": {
                "future_q1_2025_revenue_range": "$39,500,000,000-$41,800,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"future_full_year_2025_expenses\": \"full year 2025 total expenses guidance range fully written out with commas with a dash between the range no spaces and dollar sign on both numbers\"\n  \"future_full_year_2025_capex\": \"full year 2025 capital expenditures guidance range fully written out with commas with a dash between the range no spaces and dollar sign on both numbers\"\n}\n"
            },
            "expectation": {
                "future_full_year_2025_expenses": "$114,000,000,000-$119,000,000,000",
                "future_full_year_2025_capex": "$60,000,000,000-$65,000,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"tax_rate_range\": \"full year 2025 tax rate guidance range fully written out with commas with a dash between the range no spaces and a percentage sign on the last number\"\n  \"legal_accrual_reduction\": \"exact reduction in legal accruals as mentioned in Q4 fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "tax_rate_range": "12-15%",
                "legal_accrual_reduction": "$1,550,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"llama4_reasoning_model\": \"yes or no - will Llama 4 be released with a reasoning model?\",\n}\n"
            },
            "expectation": {
                "llama4_reasoning_model": "yes"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"andromeda_complexity_increase\": \"increase in model complexity enabled by Andromeda number only comma separated number\",\n  \"andromeda_quality_increase\": \"percentage increase in ad quality due to Andromeda number with a percentage sign on the last number nothing else\"\n}\n"
            },
            "expectation": {
                "andromeda_complexity_increase": "10,000",
                "andromeda_quality_increase": "8%"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"advantage_shopping_revenue\": \"revenue from Advantage+ shopping campaigns as stated in the report fully written out with commas and dollar sign\",\n  \"advantage_shopping_growth\": \"year-over-year growth percentage of Advantage+ shopping campaigns as stated in the report with a percentage sign on the last number nothing else\"\n}\n"
            },
            "expectation": {
                "advantage_shopping_revenue": "$20,000,000,000",
                "advantage_shopping_growth": "70%"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"ceo\": \"full name of the CEO\"\n  \"cfo\": \"full name of the CFO\"\n}\n"
            },
            "expectation": {
                "ceo": "Mark Zuckerberg",
                "cfo": "Susan Li"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"ai_assistant_target_users\": \"number of users that the AI assistant is expected to reach in 2025 fully written out with commas\",\n  \"meta_ai_current_usage\": \"current number of monthly active users for Meta AI fully written out with commas\"\n}\n"
            },
            "expectation": {
                "ai_assistant_target_users": "1,000,000,000",
                "meta_ai_current_usage": "700,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"expected_glasses_units_range\": \"range of units sold by breakout consumer electronics products in their third generation, fully written out with commas and a dash between the numbers with no spaces\",\n  \"rayban_glasses_description\": \"exact complete sentence from the report describing the performance and market reception of Ray-Ban Meta AI glasses, including all punctuation and phrasing\"\n}\n"
            },
            "expectation": {
                "expected_glasses_units_range": "5,000,000-10,000,000",
                "rayban_glasses_description": "Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the trajectory for AI glasses as a category."
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"ai_datacenter_capacity\": \"exact capacity of the AI datacenter being built as mentioned in the report (in GW, with no additional text)\"\n}\n"
            },
            "expectation": {
                "ai_datacenter_capacity": "2GW"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"free_cash_flow\": \"free cash flow as stated in the report fully written out with commas and dollar sign\",\n  \"dividends_paid\": \"dividends paid to shareholders as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "free_cash_flow": "$13,200,000,000",
                "dividends_paid": "$1,300,000,000"
            }
        },
        {
            "dynamic_variables": {
                "information_to_parse": "{\n  \"capital_expenditures\": \"capital expenditures as stated in the report fully written out with commas and dollar sign\",\n  \"cash_and_marketable_securities\": \"cash and marketable securities at year end as stated in the report fully written out with commas and dollar sign\"\n}\n"
            },
            "expectation": {
                "capital_expenditures": "$14,800,000,000",
                "cash_and_marketable_securities": "$77,800,000,000"
            }
        }
    ],
    "models": [
        {
            "model": "openai~o3-mini:low",
            "results": [
                {
                    "prompt_response": {
                        "response": "{\n  \"speakers\": [\n    \"Kenneth Dorell\",\n    \"Mark Zuckerberg\",\n    \"Susan Li\",\n    \"Operator\"\n  ]\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 5615.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.002274,
                        "errored": null
                    },
                    "execution_result": "{\n  \"speakers\": [\n    \"Kenneth Dorell\",\n    \"Mark Zuckerberg\",\n    \"Susan Li\",\n    \"Operator\"\n  ]\n}",
                    "expected_result": "{'speakers': ['Kenneth Dorell', 'Mark Zuckerberg', 'Susan Li', 'Operator', 'Brian Nowak', 'Eric Sheridan', 'Mark Shmulik', 'Justin Post', 'Douglas Anmuth', 'Ronald Josey', 'Kenneth Gawrelski', 'Ross Sandler']}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"speakers\": \"json list of full names of speakers on the call sorted by the order they spoke, no duplicates, include Operator\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": false,
                    "index": 1
                },
                {
                    "prompt_response": {
                        "response": "{\"ceo\": \"Mark Zuckerberg\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3598.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001873,
                        "errored": null
                    },
                    "execution_result": "{\"ceo\": \"Mark Zuckerberg\"}",
                    "expected_result": "{'ceo': 'Mark Zuckerberg'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"ceo\": \"full name of the CEO\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 2
                },
                {
                    "prompt_response": {
                        "response": "{\"cfo\": \"Susan Li\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2636.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001873,
                        "errored": null
                    },
                    "execution_result": "{\"cfo\": \"Susan Li\"}",
                    "expected_result": "{'cfo': 'Susan Li'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"cfo\": \"full name of the CFO\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 3
                },
                {
                    "prompt_response": {
                        "response": "{\"company\": \"Meta Platforms, Inc. (META)\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 7196.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001877,
                        "errored": null
                    },
                    "execution_result": "{\"company\": \"Meta Platforms, Inc. (META)\"}",
                    "expected_result": "{'company': 'Meta Platforms, Inc. (META)'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"company\": \"name of the company exactly as listed in the report\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 4
                },
                {
                    "prompt_response": {
                        "response": "{\"conference_call_title\": \"Fourth Quarter 2024 Results Conference Call\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3178.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001916,
                        "errored": null
                    },
                    "execution_result": "{\"conference_call_title\": \"Fourth Quarter 2024 Results Conference Call\"}",
                    "expected_result": "{'conference_call_title': 'Fourth Quarter 2024 Results Conference Call'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"conference_call_title\": \"exact title of the conference call\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 5
                },
                {
                    "prompt_response": {
                        "response": "{\"report_date\": \"January 29th, 2025\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2628.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001878,
                        "errored": null
                    },
                    "execution_result": "{\"report_date\": \"January 29th, 2025\"}",
                    "expected_result": "{'report_date': 'January 29th, 2025'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"report_date\": \"the date of the conference call as mentioned in the transcript\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 6
                },
                {
                    "prompt_response": {
                        "response": "{\"quarter\": \"Q4 2024\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2626.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001875,
                        "errored": null
                    },
                    "execution_result": "{\"quarter\": \"Q4 2024\"}",
                    "expected_result": "{'quarter': 'Q4 2024'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"quarter\": \"the quarter being reported in this format: QN YYYY\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 7
                },
                {
                    "prompt_response": {
                        "response": "{\"total_revenue\": \"$48.4 billion\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2623.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001915,
                        "errored": null
                    },
                    "execution_result": "{\"total_revenue\": \"$48.4 billion\"}",
                    "expected_result": "{'total_revenue': '$48,400,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"total_revenue\": \"Q4 total revenue as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": false,
                    "index": 8
                },
                {
                    "prompt_response": {
                        "response": "{\"total_expenses\": \"$25,000,000,000\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2622.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001917,
                        "errored": null
                    },
                    "execution_result": "{\"total_expenses\": \"$25,000,000,000\"}",
                    "expected_result": "{'total_expenses': '$25,000,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"total_expenses\": \"Q4 total expenses as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 9
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"operating_income\": \"$23,400,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2625.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001919,
                        "errored": null
                    },
                    "execution_result": "{\n  \"operating_income\": \"$23,400,000,000\"\n}",
                    "expected_result": "{'operating_income': '$23,400,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"operating_income\": \"Q4 operating income as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 10
                },
                {
                    "prompt_response": {
                        "response": "{\"operating_margin\": \"48%\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3281.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001914,
                        "errored": null
                    },
                    "execution_result": "{\"operating_margin\": \"48%\"}",
                    "expected_result": "{'operating_margin': '48%'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"operating_margin\": \"Q4 operating margin percentage as stated in the report with a percentage sign on the last number nothing else\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 11
                },
                {
                    "prompt_response": {
                        "response": "{\"net_income\": \"$20,800,000,000\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 7568.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001916,
                        "errored": null
                    },
                    "execution_result": "{\"net_income\": \"$20,800,000,000\"}",
                    "expected_result": "{'net_income': '$20,800,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"net_income\": \"Q4 net income as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 12
                },
                {
                    "prompt_response": {
                        "response": "{\"earnings_per_share\": \"$8.02\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3396.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001915,
                        "errored": null
                    },
                    "execution_result": "{\"earnings_per_share\": \"$8.02\"}",
                    "expected_result": "{'earnings_per_share': '$8.02'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"earnings_per_share\": \"Q4 earnings per share as stated in the report exact number and nothing else with dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 13
                },
                {
                    "prompt_response": {
                        "response": "{\"employee_count\": \"74,000\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2811.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001913,
                        "errored": null
                    },
                    "execution_result": "{\"employee_count\": \"74,000\"}",
                    "expected_result": "{'employee_count': '74,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"employee_count\": \"exact number of employees at year end comma separated\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 14
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"family_of_apps_ad_revenue\": \"$46,800,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 8324.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.00196,
                        "errored": null
                    },
                    "execution_result": "{\n  \"family_of_apps_ad_revenue\": \"$46,800,000,000\"\n}",
                    "expected_result": "{'family_of_apps_ad_revenue': '$46,800,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"family_of_apps_ad_revenue\": \"Q4 Family of Apps ad revenue as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 15
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"family_of_apps_other_revenue\": \"$519,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3015.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001959,
                        "errored": null
                    },
                    "execution_result": "{\n  \"family_of_apps_other_revenue\": \"$519,000,000\"\n}",
                    "expected_result": "{'family_of_apps_other_revenue': '$519,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"family_of_apps_other_revenue\": \"Q4 Family of Apps other revenue as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 16
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"reality_labs_revenue\": \"$1,100,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3225.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001998,
                        "errored": null
                    },
                    "execution_result": "{\n  \"reality_labs_revenue\": \"$1,100,000,000\"\n}",
                    "expected_result": "{'reality_labs_revenue': '$1,100,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"reality_labs_revenue\": \"Q4 revenue for Reality Labs as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 17
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"reality_labs_operating_loss\": \"$5,000,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 11825.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001999,
                        "errored": null
                    },
                    "execution_result": "{\n  \"reality_labs_operating_loss\": \"$5,000,000,000\"\n}",
                    "expected_result": "{'reality_labs_operating_loss': '$5,000,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"reality_labs_operating_loss\": \"operating loss for Reality Labs in Q4 as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 18
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"future_q1_2025_revenue_range\": \"$39,500,000,000-$41,800,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 5586.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.002007,
                        "errored": null
                    },
                    "execution_result": "{\n  \"future_q1_2025_revenue_range\": \"$39,500,000,000-$41,800,000,000\"\n}",
                    "expected_result": "{'future_q1_2025_revenue_range': '$39,500,000,000-$41,800,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"future_q1_2025_revenue_range\": \"Q1 2025 revenue guidance range as stated in the report fully written out with commas with a dash between the range no spaces and dollar sign on both numbers\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 19
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"future_full_year_2025_expenses\": \"$114,000,000,000-$119,000,000,000\",\n  \"future_full_year_2025_capex\": \"$60,000,000,000-$65,000,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 4556.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.002106,
                        "errored": null
                    },
                    "execution_result": "{\n  \"future_full_year_2025_expenses\": \"$114,000,000,000-$119,000,000,000\",\n  \"future_full_year_2025_capex\": \"$60,000,000,000-$65,000,000,000\"\n}",
                    "expected_result": "{'future_full_year_2025_expenses': '$114,000,000,000-$119,000,000,000', 'future_full_year_2025_capex': '$60,000,000,000-$65,000,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"future_full_year_2025_expenses\": \"full year 2025 total expenses guidance range fully written out with commas with a dash between the range no spaces and dollar sign on both numbers\"\n  \"future_full_year_2025_capex\": \"full year 2025 capital expenditures guidance range fully written out with commas with a dash between the range no spaces and dollar sign on both numbers\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 20
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"tax_rate_range\": \"12-15%\",\n  \"legal_accrual_reduction\": \"$1,550,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 18989.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.002087,
                        "errored": null
                    },
                    "execution_result": "{\n  \"tax_rate_range\": \"12-15%\",\n  \"legal_accrual_reduction\": \"$1,550,000,000\"\n}",
                    "expected_result": "{'tax_rate_range': '12-15%', 'legal_accrual_reduction': '$1,550,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"tax_rate_range\": \"full year 2025 tax rate guidance range fully written out with commas with a dash between the range no spaces and a percentage sign on the last number\"\n  \"legal_accrual_reduction\": \"exact reduction in legal accruals as mentioned in Q4 fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 21
                },
                {
                    "prompt_response": {
                        "response": "{\"llama4_reasoning_model\": \"yes\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3117.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001915,
                        "errored": null
                    },
                    "execution_result": "{\"llama4_reasoning_model\": \"yes\"}",
                    "expected_result": "{'llama4_reasoning_model': 'yes'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"llama4_reasoning_model\": \"yes or no - will Llama 4 be released with a reasoning model?\",\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 22
                },
                {
                    "prompt_response": {
                        "response": "{\"andromeda_complexity_increase\": \"10000\", \"andromeda_quality_increase\": \"8%\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 7757.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001929,
                        "errored": null
                    },
                    "execution_result": "{\"andromeda_complexity_increase\": \"10000\", \"andromeda_quality_increase\": \"8%\"}",
                    "expected_result": "{'andromeda_complexity_increase': '10,000', 'andromeda_quality_increase': '8%'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"andromeda_complexity_increase\": \"increase in model complexity enabled by Andromeda number only comma separated number\",\n  \"andromeda_quality_increase\": \"percentage increase in ad quality due to Andromeda number with a percentage sign on the last number nothing else\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": false,
                    "index": 23
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"advantage_shopping_revenue\": \"$20,000,000,000\",\n  \"advantage_shopping_growth\": \"70%\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2738.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001972,
                        "errored": null
                    },
                    "execution_result": "{\n  \"advantage_shopping_revenue\": \"$20,000,000,000\",\n  \"advantage_shopping_growth\": \"70%\"\n}",
                    "expected_result": "{'advantage_shopping_revenue': '$20,000,000,000', 'advantage_shopping_growth': '70%'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"advantage_shopping_revenue\": \"revenue from Advantage+ shopping campaigns as stated in the report fully written out with commas and dollar sign\",\n  \"advantage_shopping_growth\": \"year-over-year growth percentage of Advantage+ shopping campaigns as stated in the report with a percentage sign on the last number nothing else\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 24
                },
                {
                    "prompt_response": {
                        "response": "{\"ceo\": \"Mark Zuckerberg\", \"cfo\": \"Susan Li\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2609.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.00188,
                        "errored": null
                    },
                    "execution_result": "{\"ceo\": \"Mark Zuckerberg\", \"cfo\": \"Susan Li\"}",
                    "expected_result": "{'ceo': 'Mark Zuckerberg', 'cfo': 'Susan Li'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"ceo\": \"full name of the CEO\"\n  \"cfo\": \"full name of the CFO\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 25
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"ai_assistant_target_users\": \"1,000,000,000\",\n  \"meta_ai_current_usage\": \"700,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2862.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001971,
                        "errored": null
                    },
                    "execution_result": "{\n  \"ai_assistant_target_users\": \"1,000,000,000\",\n  \"meta_ai_current_usage\": \"700,000,000\"\n}",
                    "expected_result": "{'ai_assistant_target_users': '1,000,000,000', 'meta_ai_current_usage': '700,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"ai_assistant_target_users\": \"number of users that the AI assistant is expected to reach in 2025 fully written out with commas\",\n  \"meta_ai_current_usage\": \"current number of monthly active users for Meta AI fully written out with commas\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 26
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"expected_glasses_units_range\": \"5-10 million\",\n  \"rayban_glasses_description\": \"Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the trajectory for AI glasses as a category.\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 5581.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.002103,
                        "errored": null
                    },
                    "execution_result": "{\n  \"expected_glasses_units_range\": \"5-10 million\",\n  \"rayban_glasses_description\": \"Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the trajectory for AI glasses as a category.\"\n}",
                    "expected_result": "{'expected_glasses_units_range': '5,000,000-10,000,000', 'rayban_glasses_description': 'Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the trajectory for AI glasses as a category.'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"expected_glasses_units_range\": \"range of units sold by breakout consumer electronics products in their third generation, fully written out with commas and a dash between the numbers with no spaces\",\n  \"rayban_glasses_description\": \"exact complete sentence from the report describing the performance and market reception of Ray-Ban Meta AI glasses, including all punctuation and phrasing\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": false,
                    "index": 27
                },
                {
                    "prompt_response": {
                        "response": "{\"ai_datacenter_capacity\": \"2GW\"}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 2609.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001915,
                        "errored": null
                    },
                    "execution_result": "{\"ai_datacenter_capacity\": \"2GW\"}",
                    "expected_result": "{'ai_datacenter_capacity': '2GW'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"ai_datacenter_capacity\": \"exact capacity of the AI datacenter being built as mentioned in the report (in GW, with no additional text)\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 28
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"free_cash_flow\": \"$13,200,000,000\",\n  \"dividends_paid\": \"$1,300,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 3435.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.001932,
                        "errored": null
                    },
                    "execution_result": "{\n  \"free_cash_flow\": \"$13,200,000,000\",\n  \"dividends_paid\": \"$1,300,000,000\"\n}",
                    "expected_result": "{'free_cash_flow': '$13,200,000,000', 'dividends_paid': '$1,300,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"free_cash_flow\": \"free cash flow as stated in the report fully written out with commas and dollar sign\",\n  \"dividends_paid\": \"dividends paid to shareholders as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 29
                },
                {
                    "prompt_response": {
                        "response": "{\n  \"capital_expenditures\": \"$14,800,000,000\",\n  \"cash_and_marketable_securities\": \"$77,800,000,000\"\n}",
                        "tokens_per_second": 0.0,
                        "provider": "openai",
                        "total_duration_ms": 4033.0,
                        "load_duration_ms": 0.0,
                        "inputAndOutputCost": 0.002012,
                        "errored": null
                    },
                    "execution_result": "{\n  \"capital_expenditures\": \"$14,800,000,000\",\n  \"cash_and_marketable_securities\": \"$77,800,000,000\"\n}",
                    "expected_result": "{'capital_expenditures': '$14,800,000,000', 'cash_and_marketable_securities': '$77,800,000,000'}",
                    "input_prompt": "<purpose>\n    Given the quarterly report, extract the information requested by the user.\n</purpose>\n\n<instructions>\n    <instruction>Generate only the information requested by the user.</instruction>\n    <instruction>Respond in JSON format with the exact keys requested by the user. </instruction>\n    <instruction>Use the key and the value to understand what the user is asking for. They will embed the outcome in the value.</instruction>\n    <instruction>Replace the value with the answer requested by the user.</instruction>\n    <instruction>Do not include any other text. Respond only with the JSON object.</instruction>\n</instructions>\n\n<quarterly-report>\n  1\n  Meta Platforms, Inc. (META)\n  Fourth Quarter 2024 Results Conference Call\n  January 29th, 2025\n  Kenneth Dorell, Director, Investor Relations\n  Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024\n  earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and\n  Susan Li, CFO.\n  Before we get started, I would like to take this opportunity to remind you that our remarks today\n  will include forward‐looking statements. Actual results may differ materially from those\n  contemplated by these forward‐looking statements.\n  Factors that could cause these results to differ materially are set forth in today’s earnings press\n  release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking\n  statements that we make on this call are based on assumptions as of today and we undertake no\n  obligation to update these statements as a result of new information or future events.\n  During this call we will present both GAAP and certain non‐GAAP financial measures. A\n  reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The\n  earnings press release and an accompanying investor presentation are available on our website at\n  investor.atmeta.com.\n  And now, I’d like to turn the call over to Mark.\n  Mark Zuckerberg, CEO\n  Thanks Ken and thanks everyone for joining today.\n  We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our\n  apps each day. This is going to be a really big year. I know it always feels like every year is a big\n  year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to\n  be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense,\n  because we have about 48 weeks to get on the trajectory that we want to be on.\n  In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant\n  reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is\n  already used by more people than any other assistant, and once a service reaches that kind of\n  scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this\n  year with a unique vision focused on personalization. We believe that people don't all want to use\n  the same AI -- people want their AI to be personalized to their context, their interests, their\n  personality, their culture, and how they think about the world. I don't think that there's just going\n  to be one big AI that everyone uses that does the same thing. People are going to get to choose\n  how their AI works and what it looks like for them. I continue to think that this is going to be one of\n  the most transformative products that we’ve made. We have some fun surprises that I think\n  people are going to like this year.\n  I think this will very well be the year when Llama and open source become the most advanced and\n  widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done \n  2\n  with pre-training and our reasoning models and larger model are looking good too. Our goal with\n  Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to\n  lead. Llama 4 will be natively multimodal -- it's an omni-model -- and it will have agentic\n  capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking\n  forward to sharing more of our plan for the year on that over the next couple of months.\n  I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent\n  that has coding and problem-solving abilities of around a good mid-level engineer. This is going to\n  be a profound milestone and potentially one of the most important innovations in history, as well\n  as over time, potentially a very large market. Whichever company builds this first I think is going to\n  have a meaningful advantage in deploying it to advance their AI research and shape the field. So\n  that's another reason why I think that this year is going to set the course for the future.\n  Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the\n  trajectory for AI glasses as a category. Many breakout products in the history of consumer\n  electronics have sold 5-10 million units in their third generation. This will be a defining year that\n  determines if we're on a path towards many hundreds of millions and eventually billions of AI\n  glasses -- and glasses being the next computing platform like we've been talking about for some\n  time -- or if this is just going to be a longer grind. But it's great overall to see people recognizing\n  that these glasses are the perfect form factor for AI -- as well as just great, stylish glasses.\n  These are all big investments -- especially the hundreds of billions of dollars that we will invest in\n  AI infrastructure over the long term. I announced last week that we expect to bring online almost\n  1GW of capacity this year, and we're building a 2GW and potentially bigger AI datacenter that is so\n  big that it’ll cover a significant part of Manhattan if it were placed there.\n  We're planning to fund all this by at the same time investing aggressively in initiatives that use\n  these AI advances to increase revenue growth. We've put together a plan that will hopefully\n  accelerate the pace of these initiatives over the next few years. That’s what a lot of our new\n  headcount growth is going towards. And how well we execute on this will also determine our\n  financial trajectory over the next few years.\n  There are a number of other important product trends related to our family of apps that I think\n  we’re going to know more about this year as well. We're going to learn what's going to happen\n  with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue\n  growing. I expect Threads to continue on its trajectory to become the leading discussion platform\n  and eventually reach 1 billion people over the next several years. Threads now has more than 320\n  million monthly actives and has been adding more than 1 million sign-ups per day. I expect\n  WhatsApp to continue gaining share and making progress towards becoming the leading\n  messaging platform in the US like it is in a lot of the rest of the world. WhatsApp now has more\n  than 100 million monthly actives in the US. Facebook is used by more than 3 billion monthly\n  actives and we're focused on growing its cultural influence. I'm excited this year to get back to\n  some OG Facebook.\n  This is also going to be a pivotal year for the metaverse. The number of people using Quest and\n  Horizon has been steadily growing -- and this is the year when a number of the long-term\n  investments that we've been working on that will make the metaverse more visually stunning and\n  inspiring will really start to land. So I think we’re going to know a lot more about Horizon's\n  trajectory by the end of this year.\n  3\n  This is also going to be a big year for redefining our relationship with governments. We now have a\n  US administration that is proud of our leading companies, prioritizes American technology\n  winning, and that will defend our values and interests abroad. And I'm optimistic about the\n  progress and innovation that this can unlock.\n  So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen\n  our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to\n  accelerate our business, and building the future of social media, we have a lot to do. I think we're\n  going to build some awesome things that shape the future of human connection. As always, I'm\n  grateful for everyone who is on this journey with us. Thank you and here’s Susan.\n  Susan Li, CFO\n  Thanks Mark and good afternoon everyone.\n  Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless\n  otherwise noted.\n  Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis.\n  Q4 total expenses were $25.0 billion, up 5% compared to last year. Before I cover the specific cost\n  lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point\n  favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs.\n  In terms of the specific line items:\n  Cost of revenue increased 15%, driven mostly by higher infrastructure costs.\n  R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs,\n  which were partially offset by lower restructuring costs.\n  Marketing & Sales were approximately flat year-over-year.\n  G&A decreased 67% driven mostly by lower legal-related expenses due to a $1.55B reduction in\n  legal accruals related to certain legal proceedings.\n  We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily\n  driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as\n  well as regulation and compliance.\n  Fourth quarter operating income was $23.4 billion, representing a 48% operating margin.\n  Our tax rate for the quarter was 12%.\n  Net income was $20.8 billion or $8.02 per share.\n  Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by\n  investments in servers, data centers and network infrastructure. \n  4\n  Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year\n  with $77.8 billion in cash and marketable securities and $28.8 billion in debt.\n  Moving now to our segment results.\n  I’ll begin with our Family of Apps segment.\n  Our community across the Family of Apps continues to grow, and we estimate more than 3.3\n  billion people used at least one of our Family of Apps on a daily basis in December.\n  Q4 Total Family of Apps revenue was $47.3 billion, up 21% year over year.\n  Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency\n  basis.\n  Within ad revenue, the online commerce vertical was the largest contributor to year-over-year\n  growth.\n  On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by\n  Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%.\n  In Q4, the total number of ad impressions served across our services increased 6% and the\n  average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing\n  growth benefited from increased advertiser demand, in part driven by improved ad performance.\n  This was partially offset by impression growth, particularly from lower-monetizing regions and\n  surfaces.\n  Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging\n  revenue growth from our WhatsApp Business Platform.\n  We continue to direct the majority of our investments toward the development and operation of\n  our Family of Apps. In Q4, Family of Apps expenses were $19.0 billion, representing 76% of our\n  overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure\n  costs and employee compensation, which were partially offset by lower legal-related expenses.\n  Family of Apps operating income was $28.3 billion, representing a 60% operating margin.\n  Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1%\n  year-over-year.\n  Reality Labs expenses were $6.0 billion, up 6% year-over-year driven primarily by higher\n  infrastructure costs and employee compensation, partially offset by lower restructuring costs.\n  Reality Labs operating loss was $5.0 billion.\n  Turning now to the business outlook. There are two primary factors that drive our revenue\n  performance: our ability to deliver engaging experiences for our community, and our effectiveness\n  at monetizing that engagement over time.\n  On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-overyear, both globally and in the United States. In Q4, global video time grew at double digit \n  5\n  percentages year-over-year on Instagram, and we’re seeing particular strength in the US on\n  Facebook, where video time spent was also up double digit rates year-over-year. We see\n  continued opportunities to drive video growth in 2025 through ongoing optimizations to our\n  ranking systems. We’re also making several product bets that are focused on setting up our\n  platforms for longer-term success.\n  Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in\n  recommendations to help smaller creators get discovered. We also want to ensure creators have a\n  place to experiment with their content, so we introduced a new feature in Q4 that allows creators\n  to first share a Reel with people who don’t follow them. This allows them to test content and see\n  what performs best before deciding to share it with their followers, and also helps introduce them\n  to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks,\n  we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it\n  easier for creators to make great Reels on their phone.\n  Another focus is making it easier for people to connect over content. Reels are already reshared\n  over 4.5 billion times a day, and we’ve been introducing more features that bring together the\n  social and entertainment aspects of Instagram. In the US, we recently launched a new destination\n  in Reels that consists of content your friends have left a note on or liked. We’re seeing very\n  positive early results and will look to expand this globally in the coming months.\n  On Threads, we made tremendous progress in 2024 and our focus this year is establishing\n  Threads as the place people come to keep up with what they care about. We’re making a number\n  of updates to our recommendation systems to prioritize more recent posts, surface content from\n  top creators, and ensure people see more of the content from accounts they follow. We will also\n  continue improving custom feeds so people can build personalized feeds on topics they’re\n  interested in.\n  Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now\n  introducing updates that will enable Meta AI to deliver more personalized and relevant responses\n  by remembering certain details from people’s prior queries and considering what they engage with\n  on Facebook and Instagram to develop better intuition for their interests and preferences.\n  Now to the second driver of our revenue performance: increasing monetization efficiency.\n  The first part of this work is optimizing the level of ads within organic engagement.\n  We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply\n  on each of our surfaces to deliver ads at the time and place they will be most relevant to people.\n  For example, we are continuing to better personalize when ads show up, including the optimal\n  locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the\n  user and revenue. This is enabling efficient supply growth.\n  Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads,\n  which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads\n  will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue\n  growth in 2025.\n  The second part of increasing monetization efficiency is improving marketing performance. \n  6\n  The ongoing enhancements to our ads ranking systems are an important driver of this work.\n  In the second half of 2024, we introduced an innovative new machine learning system in\n  partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000x increase\n  in the complexity of models we use for ads retrieval, which is the part of the ranking process where\n  we narrow down a pool of tens of millions of ads to the few thousand we consider showing\n  someone. The increase in model complexity is enabling us to run far more sophisticated prediction\n  models to better personalize which ads we show someone. This has driven an 8% increase in the\n  quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently\n  process larger volumes of ads also positions us well for the future as advertisers use our\n  generative AI tools to create and test more ads.\n  Another way we’re delivering value for advertisers is through increased automation of their ad\n  campaigns with Advantage+.\n  Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20\n  billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and\n  interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a\n  new streamlined campaign creation flow so advertisers no longer need to choose between running\n  a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for\n  sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow\n  more advertisers to take advantage of the performance Advantage+ offers while still having the\n  ability to further customize aspects of their campaigns when they need to. We plan to expand to\n  more advertisers in the coming months before fully rolling it out later in the year.\n  Advantage+ creative is another area where we’re seeing momentum. More than 4 million\n  advertisers are now using at least one of our generative AI ad creative tools, up from one million\n  six months ago. There has been significant early adoption of our first video generation tool that we\n  rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it\n  monthly.\n  Next, I would like to discuss our approach to capital allocation. Our primary focus remains\n  investing capital back into the business, with infrastructure and talent being our top priorities.\n  On the first, we expect compute will be central to many of the opportunities we’re pursuing as we\n  advance the capabilities of Llama, drive increased usage of generative AI products and features\n  across our platform, and fuel core ads and organic engagement initiatives.\n  We’re working to meet the growing capacity needs for these services by both scaling our\n  infrastructure footprint and increasing the efficiency of our workloads. Another way we’re\n  pursuing efficiencies is by extending the useful lives of our servers and associated networking\n  equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI\n  servers for a longer period of time before replacing them, which we estimate will be approximately\n  five and a half years. This will deliver savings in annual capex and resulting depreciation expense,\n  which is already included in our guidance.\n  Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we\n  can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we\n  started deploying MTIA to our ranking and recommendation inference workloads for ads and\n  organic content. We expect to further ramp adoption of MTIA for these use cases throughout \n  7\n  2025 before extending our custom silicon efforts to training workloads for ranking and\n  recommendations next year.\n  From a hiring standpoint, our focus continues to be on adding technical talent to support our\n  strategic priorities.\n  In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D\n  function. The remaining growth was primarily in cost of revenue as we added infrastructure\n  headcount to support our data center operations.\n  In 2025, we expect headcount growth will continue to be primarily driven by technical roles across\n  our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as\n  regulation and compliance. We anticipate headcount growth in our business functions will remain\n  relatively limited.\n  To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re\n  supporting this by building tools to help our engineering base be more productive. As part of our\n  efficiency focus over the past two years, we’ve made significant improvements in our internal\n  processes and developer tools and introduced new tools like our AI-powered coding assistant,\n  which is helping our engineers write code more quickly. Looking forward, we expect that the\n  continuous advancements in Llama’s coding capabilities will provide even greater leverage to our\n  engineers, and we are focused on expanding its capabilities to not only assist our engineers in\n  writing and reviewing our code, but also to begin generating code changes to automate tool\n  updates and improve the quality of our code base.\n  Finally, we expect our strong financial position will enable us to support these investments while\n  continuing to return capital to shareholders through share repurchases and dividends.\n  Moving to our financial outlook.\n  We expect first quarter 2025 total revenue to be in the range of $39.5-41.8 billion. This reflects 8-\n  15% year-over-year growth, or 11-18% growth on a constant currency basis as our guidance\n  assumes foreign currency is an approximately 3% headwind to year-over-year total revenue\n  growth, based on current exchange rates. This also reflects the effect of lapping leap day in the\n  first quarter of 2024. While we are not providing a full year 2025 revenue outlook, we expect the\n  investments we’re making in our core business this year will give us an opportunity to continue\n  delivering strong revenue growth throughout 2025.\n  Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of\n  $114-119 billion.\n  We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by\n  higher operating expenses and depreciation. We expect employee compensation to be the\n  second-largest factor as we add technical talent in the priority areas that I referenced earlier.\n  Turning now to the capex outlook. We anticipate our full year 2025 capital expenditures will be in\n  the range of $60-65 billion. We expect capex growth in 2025 will be driven by increased\n  investment to support both our generative AI efforts and our core business. The majority of our\n  capex in 2025 will continue to be directed toward our core business.\n  8\n  On to tax. Absent any changes to our tax landscape, we expect our full year 2025 tax rate to be in\n  the range of 12-15%.\n  In addition, we continue to monitor an active regulatory landscape, including legal and regulatory\n  headwinds in the EU and the US that could significantly impact our business and our financial\n  results.\n  In closing, this was a good year for our company, with investments across our priority areas\n  delivering strong business performance and innovative new products for our community. We have\n  a compelling set of opportunities to invest in this year, which we expect will help us drive\n  continued strong growth and develop transformative technologies that shape the future of our\n  company and of the industry.\n  With that, Krista, let’s open up the call for questions.\n  Operator: Thank you. We will now open the lines for a question and answer session. To\n  ask a question, please press star one on your touchtone phone. To withdraw\n  your question, again press star one. Please limit yourself to one question.\n  Please pick up your handset before asking your question to ensure clarity. If\n  you are streaming today’s call, please mute your computer speakers. And our\n  first question comes from the line of Brian Nowak with Morgan Stanley. Please\n  go ahead.\n  Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this\n  year and all the innovation to come. I know there’s a lot of announcements over\n  the course of the year, but I wonder if you could just share a few sort of highlevel examples of your vision on new potential use cases and offerings that\n  could drive utility for your users and value for your advertisers as you sort of\n  think about Llama 4 and Meta AI changing throughout 2025?\n  And then the second one on custom silicon, maybe a question for either of you.\n  Just any learnings on the difference between your custom silicon and thirdparty chips in your ranking models and results? And how should we think about\n  the main gating factors as to how quickly you’d be able to move a higher\n  percentage of your engagement to your custom silicon?\n  Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean\n  we’re very focused on Meta AI as a highly intelligent and personalized assistant\n  that you can access across our apps. There’s a website, you can access it\n  outside of our apps, too.\n  I think that the quality of this is just - it’s going to keep on improving and\n  improved a lot over the last year. We’re also finding more ways that it’s useful\n  to integrate it into our services to help more people discover it.\n  I think that that’s undoubtedly why so many hundreds of millions of people are\n  using it today, is because it’s kind of easy to discover what we’re doing and\n  then keep using it.\n  9\n  I want to keep some surprises and fun for the stuff that we’re going to release\n  this year. I gave a bit of detail on what we’re planning to do with Llama 4 that\n  I’m sure technical people will enjoy because we haven’t talked about that\n  before.\n  But I’m going to refrain from adding a whole lot more on what we’re launching\n  this year. But it’s the different things that I talked about. It’s Meta AI. I do\n  expect Llama 4 to be a very exciting set of releases. It’s not just one thing. Just\n  like with Llama 3, there were kind of a few different models at different dates, I\n  think we’ll see that with Llama 4 too. And then the AI engineer piece, I’m really\n  excited about it.\n  I mean I don’t know that that’s going to be an external product anytime soon.\n  But I think for what we’re working on, our goal is to advance AI research and\n  advance our own development internally. And I think it’s just going to be a very\n  profound thing.\n  So I mean that’s something that I think will show up through making our\n  products better over time. But -- and then as that works, there will potentially\n  be a market opportunity down the road.\n  But I mean for now and this year, we’re really -- I think this is -- I don’t think\n  you’re going to see this year like an AI engineer that is extremely widely\n  deployed, changing all of development.\n  I think this is going to be the year where that really starts to become possible\n  and lays the groundwork for a much more dramatic change in ‘26 and beyond. I\n  don’t know, yeah, that’s kind of -- that’s kind of it.\n  Susan Li: Brian, I’m happy to take your second question about custom silicon. So first of\n  all, we expect that we are continuing to purchase third-party silicon from\n  leading providers in the industry.\n  And we are certainly committed to those long-standing partnerships, but we’re\n  also very invested in developing our own custom silicon for unique workloads,\n  where off-the-shelf silicon isn’t necessarily optimal and specifically because\n  we’re able to optimize the full stack to achieve greater compute efficiency and\n  performance per cost and power because our workloads might require a\n  different mix of memory versus network, bandwidth versus compute, and so\n  we can optimize that really to the specific needs of our different types of\n  workloads.\n  Right now the in-house MTIA program is focused on supporting our core\n  ranking and recommendation inference workloads. We started adopting MTIA\n  in the first half of 2024 for core ranking and recommendations inference.\n  We’ll continue ramping adoption for those workloads over the course of 2025\n  as we use it for both incremental capacity and to replace some GPU-based\n  servers when they reach the end of their useful lives. Next year, we’re hoping to \n  10\n  expand MTIA to support some of our core AI training workloads and over time\n  some of our Gen AI use cases.\n  Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.\n  Please go ahead.\n  Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your\n  comments on open source. Can you help us understand how your views\n  continue to evolve with respect to the competitive dynamic around your\n  approach with open source versus others in the industry? And how your\n  approach to open source could possibly bend the cost curve and improve\n  return on capital for AI over the medium to long term? Thanks so much.\n  Mark Zuckerberg: Yeah, I mean on open source, I think the best analogy for us is what we did with\n  open compute, where we weren’t first to building the system. So then by the\n  time that we got around to building it, it wasn’t really a big advantage to have it\n  be proprietary.\n  So we shared it. And then a lot of the industry adopted what we were doing,\n  contributed innovations back to it. By standardizing on it, that meant that a\n  bunch of supply chain standardized on building it, which made prices more\n  efficient for everyone.\n  I think what we see here is as Llama becomes more used, it’s more likely, for\n  example, that silicon providers and others -- other APIs and developer\n  platforms will optimize their work more for that and basically drive down the\n  costs of using it and drive improvements that we can, in some cases, use too.\n  So I think that the strategy will continue to be effective, and yeah, I mean I\n  continue to be optimistic on this. I think it’s kind of -- I think it’s working.\n  I also just think in light of some of the recent news, the new competitor\n  DeepSeek from China, I think it also just puts -- it’s one of the things that we’re\n  talking about is there’s going to be an open source standard globally.\n  And I think for our kind of national advantage, it’s important that it’s an\n  American standard. So we take that seriously and we want to build the AI\n  system that people around the world are using and I think that if anything,\n  some of the recent news has only strengthened our conviction that this is the\n  right thing for us to be focused on.\n  Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please\n  go ahead.\n  Mark Shmulik: Thank you for taking my questions. Mark, appreciate we may get an answer\n  this year. But looking out, as you kind of track the progress of smart glasses,\n  Orion and so forth, do you view that as a better form factor to get the most out\n  of the Meta AI assistant you highlighted in your opening remarks? Or is it more\n  complementary to kind of the in-app experience in the way you’ve seen people\n  use it today?\n  11\n  And then, Susan, the last few quarters, we’ve kind of seen pricing growth as the\n  dominant driver of ad revenue growth. Given the efforts you’ve highlighted\n  around driving deeper, more commercial engagement and better advertiser\n  ROI, how do we just think about the contribution of the formula for ad revenue\n  growth going forward? Thank you.\n  Mark Zuckerberg: Yeah. I mean I can talk about glasses. I mean it’s -- I mean I’ve said for a while\n  that I think that glasses are the ideal form factor for an AI device because you\n  can let an AI assistant on your glasses see what you see and hear what you\n  hear, which gives it the context to be able to understand everything that’s\n  going on in your life that you would want to talk to it about and get context on.\n  So -- but look, I think that glasses are going to be a very important computing\n  platform in the future. When phones became the primary computing platform,\n  it’s not like computers went away.\n  I think we’ll have phones for some time. But there are a lot of people in the\n  world who have glasses.\n  It’s kind of hard for me to imagine that a decade or more from now all the\n  glasses aren’t going to basically be AI glasses as well as a lot of people who\n  don’t wear glasses today, finding that to be a useful thing.\n  So I’m incredibly optimistic about this. And like I shared last year, I think one of\n  the big surprises last year was I previously thought that glasses weren’t going\n  to become a major form factor until we got these -- the full kind of holographic\n  displays that we started showing in the prototype for Orion.\n  But now I think it’s pretty clear that AI is actually going to drive at least as\n  much of the value as the holographic AR is. So that’s a cause to be excited.\n  But look, the Ray-Ban Metas were a hit. We still don’t know what the long-term\n  trajectory for this is going to be. And I think we’re going to learn a lot this year.\n  So I think that this is a really important year for that.\n  Susan Li: And I can take the second question on pricing growth. So first of all, what I\n  would say is over the long term, we think we have continued opportunity to\n  drive revenue growth across both pricing and impression growth, so both sort\n  of supply and demand dimensions. When we look at pricing, our reported\n  growth can be influenced by different factors such as supply because of the\n  auction dynamics by the mix shift of the different types of surfaces where ads\n  show up.\n  For example, services like video are lower monetization efficiency, relatively\n  speaking, and then, of course, broader macro factors.\n  But we generally expect that we are going to be able to deliver ongoing ad\n  performance improvements through a lot of the ongoing work that we’re doing\n  across our monetization roadmap and that will have the sort of effect of \n  12\n  benefiting pricing overall. And part of what I think is kind of important to think\n  about here when we think about price growth is, we really -- the average price\n  per ad as we report it, is really blending, it’s an output metric.\n  It’s blending a lot of things that are happening including what are advertisers\n  bidding for, what are their bids for those things? What is the average cost of\n  their actions? So given that there are so many different objectives that\n  advertisers can optimize for that have different values, it’s a very complex\n  metric that tries to distill that into one thing.\n  Overall, we are seeing healthy cost per action trends for advertisers for\n  whatever is the action that they are optimizing for. And we believe we’ll\n  continue to get better at driving conversions for advertisers. And when we do,\n  that will have the effect of continuing to lift CPMs over time because we’re\n  delivering more conversions per impressions served, resulting in higher value\n  impressions.\n  Operator: Your next question comes from the line of Justin Post with Bank of America.\n  Please go ahead.\n  Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned\n  political changes in the U.S. and better positioning maybe for U.S. companies\n  abroad.\n  But how do you think about it in the U.S. as far as usage and advertiser\n  adoption, you got rid of fact checking. So is -- do you think content could\n  change? Could it appeal to more users? Will that impact advertising at all?\n  And then Susan, on Meta AI, I know people are pretty excited about the use\n  case, but also thinking about the revenue case. How do you think about\n  monetizing that? Could it be CPC ads? Or how are you thinking about that?\n  Thank you.\n  Mark Zuckerberg: The question was about fact checking and our content policies. I mean look, I\n  think we’re trying to build the service that we think is the best for people.\n  I’ve believed in free expression for quite a while. People don’t want to see\n  misinformation, but you need to build an effective system that gives people\n  more context. And I think what we found over time is that the community\n  notes system, I think, is just going to be more effective than the system that\n  we had before.\n  And I’m not afraid to admit when someone does something that’s better than\n  us. I think it’s sort of our job to go and just do the best work and implement the\n  best systems.\n  So I think that there’s been a lot of people who have read this announcement as\n  if we somehow don’t care about adding context to things that are on our\n  platform that are misinformation, that’s not right.\n  13\n  I actually think that the community notes system, like what X has had for a\n  while is actually just more effective than what we were doing before. And I\n  think our product is going to get better because of it.\n  Susan Li: I would add to that, just to say, we also haven’t seen any noticeable impact\n  from our content policy changes on advertiser spend.\n  So we’re continuing to see strong advertiser demand. Again, particularly for AIpowered tools that are helping businesses maximize the value of their ad\n  spend. So our commitment to brand safety is unchanged, and we expect that\n  we will invest in our suite of tools to meet the needs of advertisers.\n  On your second question in terms of monetizing Meta AI, our initial focus for\n  Meta AI is really about building a great consumer experience, and that’s frankly,\n  where all of our energies are kind of directed to right now.\n  There will, I think, be pretty clear monetization opportunities here over time\n  including paid recommendations and including a premium offering, but that’s\n  really not where we are focused in terms of the development of Meta AI today.\n  Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan.\n  Please go ahead.\n  Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just\n  following up on open source as DeepSeek and other models potentially\n  leverage Llama or others to train faster and cheaper, how does this impact\n  Meta in your view? And what could it mean for the trajectory of investment\n  required over a multiyear period?\n  And then, Susan, just as we think about the $60 billion to $65 billion CapEx this\n  year, does the composition change much from last year when you talked about\n  servers as the largest part followed by data centers and networking\n  equipment? And how should we think about that mix between like training and\n  inference just following up on Yann’s post this week? Thanks.\n  Mark Zuckerberg: I can start on the DeepSeek question. I think there’s a number of novel things\n  that they did that I think we’re still digesting. And there are a number of things\n  that they have advances that we will hope to implement in our systems. And\n  that’s part of the nature of how this works, whether it’s a Chinese competitor\n  or not.\n  I kind of expect that every new company that has an advance -- that has a\n  launch is going to have some new advances that the rest of the field learns\n  from. And that’s sort of how the technology industry goes.\n  I don’t know -- it’s probably too early to really have a strong opinion on what\n  this means for the trajectory around infrastructure and CapEx and things like\n  that. There are a bunch of trends that are happening here all at once.\n  14\n  There’s already sort of a debate around how much of the compute\n  infrastructure that we’re using is going to go towards pretraining versus as you\n  get more of these reasoning time models or reasoning models where you get\n  more of the intelligence by putting more of the compute into inference,\n  whether just it will mix shift how we use our compute infrastructure towards\n  that.\n  That was already something that I think a lot of the -- the other labs and\n  ourselves were starting to think more about and already seemed pretty likely\n  even before this, that -- like of all the compute that we’re using, that the largest\n  pieces aren’t necessarily going to go towards pre-training.\n  But that doesn’t mean that you need less compute because one of the new\n  properties that’s emerged is the ability to apply more compute at inference\n  time in order to generate a higher level of intelligence and a higher quality of\n  service, which means that as a company that has a strong business model to\n  support this, I think that’s generally an advantage that we’re now going to be\n  able to provide a higher quality of service than others who don’t necessarily\n  have the business model to support it on a sustainable basis.\n  The other thing is just that when we’re building things like Meta AI, but also\n  how we’re implementing AI into all the feeds and ad products and things like\n  that, we’re just serving billions of people, which is different from, okay you start\n  to pretrain a model, and that model is sort of agnostic to how many people are\n  using it.\n  Like at some level, it’s going to be expensive for us to serve all of these people\n  because we are serving a lot of people. And so I’m not sure what the kind of net\n  effect of all of this is. The field continues to move quickly. There’s a lot to learn\n  from releases from basically everyone who does something interesting, not just\n  the ones over the last month.\n  We’ll continue to kind of incorporate that into what we do as well as making\n  novel contributions to the field ourselves. And I continue to think that investing\n  very heavily in CapEx and infra is going to be a strategic advantage over time.\n  It’s possible that we’ll learn otherwise at some point, but I just think it’s way too\n  early to call that. And at this point, I would bet that the ability to build out that\n  kind of infrastructure is going to be a major advantage for both the quality of\n  the service and being able to serve the scale that we want to.\n  Susan Li: I’m happy to add a little more color about our 2025 CapEx plans to your second\n  question.\n  So we certainly expect that 2025 CapEx is going to grow across all three of\n  those components you described. Servers will be the biggest growth driver,\n  that remains the largest portion of our overall CapEx budget.\n  We expect both growth in AI capacity as we support our gen AI efforts and\n  continue to invest meaningfully in core AI, but we are also expecting growth in \n  15\n  non-AI capacity as we invest in the core business including to support a higher\n  base of engagement and to refresh our existing servers.\n  On the data center side, we’re anticipating higher data center spend in 2025 to\n  be driven by build-outs of our large training clusters and our higher power\n  density data centers that are entering the core construction phase. We’re\n  expecting to use that capacity primarily for core AI and non-AI use cases.\n  On the networking side, we expect networking spend to grow in ‘25 as we build\n  higher-capacity networks to accommodate the growth in non-AI and core AIrelated traffic along with our large Gen AI training clusters.\n  We’re also investing in fiber to handle future cross-region training traffic. And\n  then in terms of the breakdown for core versus Gen AI use cases, we’re\n  expecting total infrastructure spend within each of Gen AI, non-AI and core AI\n  to increase in ‘25 with the majority of our CapEx directed to our core business\n  with some caveat that that is -- that’s not easy to measure perfectly as the\n  data centers we’re building can support AI or non-AI workloads and the GPUbased servers we procure for gen AI can be repurposed for core AI use cases\n  and so on and so forth.\n  But overall, I would reiterate what Mark said. We are committed to building\n  leading foundation models and applications. We expect that we’re going to\n  make big investments to support our training and inference objectives, and we\n  don’t know exactly where we are in the cycle of that yet.\n  Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go\n  ahead.\n  Ronald Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment\n  on getting back to the OG Facebook, and I want to understand a little bit more\n  on the use cases and how that could expand. Video is clearly a benefit. Local,\n  Marketplace, Groups have all been positive.\n  So any insights on the OG Facebook? And then back to Meta AI, given the\n  adoption we’re seeing on the 600-plus MAUs, just how has the user experience\n  evolved to? What are people doing with Meta AI? Thank you.\n  Mark Zuckerberg: Okay. So for Facebook. A lot of people use Facebook every day, and it’s an\n  important part of their lives. And I think that there are a lot of opportunities to\n  make it way more culturally influential than it is today. And I think that that’s\n  sort of a fun and interesting goal that will take our product development in\n  some interesting directions that we maybe haven’t had a focus on it as much\n  over the last several years.\n  So I don’t know that I have anything much more specific on this other than that\n  this is going to be one of my focus areas for this year. I mean I think it’s an\n  investment area and something I’m going to spend some time on.\n  16\n  It might mean that in the near term, we make some trade-offs to kind of focus\n  on some product areas of what we’re doing ahead of just kind of maximizing\n  business results in the near term on it.\n  But overall, I’m really excited about doing some exciting stuff here. And I’m not\n  going to get into many specifics now but we’ll get -- we’ll follow up on this over\n  the next, I don’t know call it, half year or a year as we start rolling stuff out and I\n  think some of this will kind of get back to how Facebook was originally used\n  back in the day. So I think it will be fun.\n  Susan Li: I’m happy to share a little bit more about Meta AI and what people are doing\n  with it. We are in a phase where we are really learning a lot from the way that\n  people engage with Meta AI.\n  So from an app perspective, WhatsApp continues to see the strongest Meta AI\n  usage across our Family of Apps. People there are using it most frequently for\n  information seeking and educational queries along with emotional support use\n  cases. Most of the WhatsApp engagement is in one-on-one threads, though we\n  see some usage in group messaging.\n  And on Facebook, which is the second largest driver of Meta AI engagement,\n  we’re seeing strong engagement from our feed deep dives integration that lets\n  people ask Meta AI questions about the content that is recommended to them.\n  So across, I would say, all query types, we continue to see signs that Meta AI is\n  helping people leverage our apps for new use cases.\n  We talked about information gathering, social interaction and communication.\n  Lots of people use it for humor and casual conversation. They use it for writing\n  and editing, research, recommendations. And as we look forward to 2025 in\n  our Meta AI roadmap, we are really focused on doing more to make it feel more\n  personalized.\n  So I would say some of the most exciting features we’re working on including\n  improving sort of the memory dimension of the Meta AI experience, where it\n  will be able to remember certain details that people share in one-on-one chats,\n  for example, and use those details to personalize its responses and then really\n  increasing its ability to deliver great content recommendations and enhance\n  really what makes Facebook and Instagram so valuable for people today.\n  Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.\n  Please go ahead.\n  Kenneth Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I\n  know you talked a little bit on the capital intensity side and the recent\n  developments, and it’s hard to see, it’s hard to tell yet where things are going.\n  But maybe you could just talk a little bit more near term, ‘25, the CapEx budget\n  you laid out or the CapEx forecast. Could you talk a little bit about the \n  17\n  constraints you’re seeing or where you’re seeing constraints, either internally\n  resources planning or externally and any one -- any parts of the ecosystem?\n  And then on the second one, I’m curious, as you think about the -- as you think\n  about your needs for hiring and we just think about -- we know you gave the\n  OpEx guide for this year.\n  But as we think about future needs for hiring, could you just give us a sense of\n  how we should think about that? You announced the performance-related\n  reductions earlier this -- for early this year. Could you just talk about how we\n  should be thinking about that ‘26, ‘27 and beyond? Thank you.\n  Susan Li: Sure. I’m happy to take both of those. So on your first question on just where\n  do we see constraints in our ability to execute against our CapEx plans,\n  obviously we are staying on top of supply availability. That is certainly one of\n  the factors that will influence our CapEx spend in 2025, but we don’t really\n  have any updates to share on supply availability right now.\n  We are planning to significantly ramp up deployment of GPUs in 2025, and\n  we’ll continue to engage with our vendors and invest in our own silicon to meet\n  those needs.\n  When you asked how to think about capital intensity, we’re not really -- as both\n  Mark and I alluded to in our prior comments, I think it is really too early to\n  determine what long-run capital intensity is going to look like. There are so\n  many different factors.\n  The pace of advancement in underlying models, how efficient can they be,\n  what is the adoption and use case of our Gen AI products, what performance\n  gains come from next-generation hardware innovations, both our own and\n  third party and then ultimately, what monetization or other efficiency gains our\n  AI investments unlock.\n  So again, I think we are -- we’re sort of early in the journey here, and we don’t\n  have -- I would say we don’t have kind of anything to share about long-run\n  capital intensity yet. Your second question was about thinking about hiring\n  needs.\n  So it’s a good segue after infrastructure, employee compensation is the next\n  largest driver of expense growth in 2025. And here, growth in employee comp\n  and headcount more broadly is primarily driven by those areas that I\n  mentioned, infrastructure monetization, generative AI, Reality Labs, and\n  regulation and compliance.\n  And those generally are more technical organizations. That means that it is a\n  higher cost base relative to business functions where we are also expecting to\n  keep headcount growth constrained. And I would say we are -- we’re focused\n  on running the company efficiently.\n  18\n  But at the same time it is -- we feel like we’re in a critical period in terms of\n  making sure that we are investing to win, and we want to make sure that we\n  staff those priority areas in a way that really positions us to best do that.\n  Kenneth Dorell: Krista, we have time for one last question.\n  Operator: And that question comes from the line of Ross Sandler with Barclays. Please go\n  ahead.\n  Ross Sandler: Yeah. One for Mark, on agents. So we all saw OpenAI’s operator demo last\n  week. So Mark, as the industry moves from chat to agentic behavior and more\n  commercial intent moves into these AI products, I guess how are you thinking\n  about monetization potential for Meta AI? And then how might Llama 4\n  reasoning help drive some of these new agentic experiences for Meta AI?\n  Thank you.\n  Mark Zuckerberg: Yeah. So I guess a couple of things that I’d say on this. One is when you’re\n  thinking about agents and reasoning, a lot of this is about being able to perform\n  multistep tasks. So right now the way that a lot of these systems work is you\n  kind of say something and then it responds and it’s almost chat like.\n  But I think that the direction that it’s going is you’re going to be able to give it\n  an intent or a task and it’s going to be able to go off and use sort of an arbitrary\n  amount of compute as much as you want to use on it to be able to do a task.\n  Some of the tasks might be pretty simple for people, go buy a specific thing.\n  Some of them might be really hard, like go write an app or optimize this code\n  and like really make it as good as possible. And that type of thing, I think, is just\n  going to start becoming more and more prevalent over the next year or two. So\n  I think it’s very exciting.\n  It sort of will feel in some ways like the current products are just getting\n  smarter and others, it will feel like sort of a new form factor because it won’t be\n  as much like chat. But it’s sort of another generation of these products.\n  So I think it’s just in general, there’s a lot to build and be excited about. I guess\n  my note of caution or just my kind of periodic reminder on our product\n  development process, if you will, is we build these products.\n  We try to scale them to reach usually a billion people or more. And it’s at that\n  point once they’re at scale that we really start focusing on monetization. So\n  sometimes we’ll experiment with monetization before, we’re running some\n  experiments with Threads now for example.\n  But we typically don’t really ramp these things up or see them as meaningfully\n  contributing to the business until we reach quite a big scale. So the thing that I\n  think is going to be meaningful this year is the kind of getting of the AI products\n  to scale.\n  19\n  Last year was sort of the introduction and starting to get it to be used. This\n  year my kind of expectation and hope is that we will be at a sufficient scale and\n  have sufficient kind of flywheel of people using it and improvement from that\n  that this will have a durable advantage.\n  But that doesn’t mean that it’s going to be a major contributor to the business\n  this year. This year, the improvements to the business are going to be taking\n  the AI methods and applying them to advertising and recommendations and\n  feeds and things like that.\n  So the actual business opportunity for Meta AI and AI Studio and business\n  agents and people interacting with these AIs remains outside of ‘25 for the\n  most part. And I think that’s an important thing for us to communicate and for\n  people to internalize as you’re thinking about our prospects here.\n  But nonetheless, we’ve run a process like this many times. We built a product.\n  We make it good. We scale it to be large. We build out the business around it.\n  That’s what we do. I’m very optimistic. But it’s going to take some time.\n  Kenneth Dorell: Thank you, everyone, for joining us today. We appreciate your time. And we\n  look forward to speaking with you again soon.\n  Operator: This concludes today’s conference call. Thank you for your participation. And\n  you may now disconnect.\n</quarterly-report>\n\n<information-to-extract>\n    {\n  \"capital_expenditures\": \"capital expenditures as stated in the report fully written out with commas and dollar sign\",\n  \"cash_and_marketable_securities\": \"cash and marketable securities at year end as stated in the report fully written out with commas and dollar sign\"\n}\n\n</information-to-extract>\n",
                    "model": "openai~o3-mini:low",
                    "correct": true,
                    "index": 30
                }
            ],
            "correct_count": 26,
            "incorrect_count": 4,
            "accuracy": 0.8666666666666667,
            "average_tokens_per_second": 0.0,
            "average_total_duration_ms": 4755.466666666666,
            "average_load_duration_ms": 0.0,
            "total_cost": 0.05872
        }
    ],
    "overall_correct_count": 26,
    "overall_incorrect_count": 4,
    "overall_accuracy": 0.8666666666666667,
    "average_tokens_per_second": 0.0,
    "average_total_duration_ms": 4755.466666666666,
    "average_load_duration_ms": 0.0
}